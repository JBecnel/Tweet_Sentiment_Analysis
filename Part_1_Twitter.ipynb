{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Collecting Data from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Twitter-logo-png-5859_-_Copy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggested Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book \"Mining the Social Web\" (https://miningthesocialweb.com/) \n",
    "can help a lot if you get stuck. \n",
    "* In fact, it is intentional that many of these questions can be answered directly from there (except for question 4)!\n",
    "* The idea is to ease you into workshop :-)\n",
    "\n",
    "**Don't forget!**\n",
    "* You will need to install the \"twitter\" library to access the Twitter API\n",
    " * pip install twitter\n",
    "\n",
    "** NOTE **\n",
    "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**.\n",
    "* **There is a package called python-twitter which is wonderful, but has a very different API.  If you get the wrong one then my examples will not work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Twitter Data with Either Streaming or Search API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic. (It would be recommended that the number of tweets should be larger than 1,000, but smaller than 10,000).\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import os\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Prof. Paffenroth has a developer account for the class.  He will provide the Twitter access tokens for\n",
    "    # each team\n",
    "    # See https://developer.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    # Team 1-3\n",
    "    CONSUMER_KEY = 'MbhA6iSZflOyYErveZzuNosE4'\n",
    "    CONSUMER_SECRET ='zvz5i6WBvS81EGkYQKMArXmnvL1vaVXXAZfskFclAeUgrU2twR'\n",
    "    OAUTH_TOKEN = '571213367-umrVxIxuWiE1uzGOw279gdsvecNQBXdab7CfqZuy'\n",
    "    OAUTH_TOKEN_SECRET = 'BI7pACPjUhZJtNNFJOZ1PLV2lflZzzEA16lLp7oFWsDvU'\n",
    "\n",
    "#     # Team 4-6\n",
    "#     CONSUMER_KEY = 'YirQT0fCiZdNIJRDWXFpwU9OU'\n",
    "#     CONSUMER_SECRET ='tJByz9a9JNwWCu3iH0P0CXa1t0AugfgFRiGifKZfD8Lgm8glgS'\n",
    "#     OAUTH_TOKEN = '571213367-lxmjiUqnyn7hmt9CL2CBMq5kRrDhMjAS7xLcaVcx'\n",
    "#     OAUTH_TOKEN_SECRET = 'FoLCxcmJWuOKLAIyXuxwtG3xpQBIM2qsUteXMCF7FxJGG'\n",
    "\n",
    "#     # Team 7-9\n",
    "#     CONSUMER_KEY = 'dyqx8OLPb7PeGkOCUOPZPHsGQ'\n",
    "#     CONSUMER_SECRET ='LM4SBcEbEHTLdJXyFRVOyBGl0TAjXmS48djm3XweYv3pBxjhwL'\n",
    "#     OAUTH_TOKEN = '571213367-W8ejT9u0M77lN52v82UeIIrgujO6smyrCNlauRee'\n",
    "#     OAUTH_TOKEN_SECRET = '7l1mvstsjPBenq6Sa9fuu8X0M3UVVgo3CF7fQBM0uPUVW'\n",
    "\n",
    "#     # Team 10-12\n",
    "#     CONSUMER_KEY = 'ijh1zy12m73JOIooMbx56tB8B'\n",
    "#     CONSUMER_SECRET ='j3fyLkFMOtcRUV3swUlzvOZayiAbSBvMXzeC2bDfdayUD0mhpM'\n",
    "#     OAUTH_TOKEN = '571213367-szzTWKXISKZeytQRl0z4P1giPdAh3OqTpfQRhj0g'\n",
    "#     OAUTH_TOKEN_SECRET = 'zx0VyALB2OO2y0vmHPcz8W612WSSnoTgGIyZcQD0w6Mh2'\n",
    "\n",
    "#     # Team 13-15\n",
    "#     CONSUMER_KEY = '9ooQGUNzPRUjdnZTZeI7wrL4Z'\n",
    "#     CONSUMER_SECRET ='jURzPZrJ33yYxyQSKXOHw66n71jdCC3ge9omXlENcZXvR3zzaq'\n",
    "#     OAUTH_TOKEN = '571213367-uIPN0Yck4PBhakA2ZksskGm37qWZ8IOMCQF5pUpa'\n",
    "#     OAUTH_TOKEN_SECRET = 'pJhzPUKJLHv0sFqHzh1iGq97p9BC9ACuIsqAbTtiiUtxz'\n",
    "\n",
    "    # Emergency - break glass to use!\n",
    "    #CONSUMER_KEY = 'KRxduP2c4L9mFv5OwezcATMd4'\n",
    "    #CONSUMER_SECRET ='Sjpg0F64ElNGMainYvclqB5sRHKfmXwUWuRDyPL26erwCF1jQ1'\n",
    "    #OAUTH_TOKEN = '571213367-ajwp6Q8xW5BkUvamespO9ezC6lK6ZjXRguwevMkI'\n",
    "    #OAUTH_TOKEN_SECRET = 'V9ydSDjQf4ELIXT0fEuSKs3blBYBj7tcFyEKGRjh383JG'\n",
    "\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "import json\n",
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See http://bit.ly/2QyGz0P and https://bit.ly/2QyGz0P\n",
    "    # for details on advanced search criteria that may be useful for\n",
    "    # keyword arguments\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "\n",
    "    statuses = search_results['statuses']\n",
    "\n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://developer.twitter.com/en/docs/basics/rate-limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "\n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "\n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "\n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=')\n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "\n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "\n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "\n",
    "    return statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "# You can change this to be any string you like!\n",
    "q = \"Samsung\"\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will thank me for this, and your students will in turn thank you :-).  This is how you can key a running list of the tweets you gather and keep a library of tweets around when things fail!  Note, this assumes that results has new data in it.  Otherwise you will just get multiple copies of the same tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendTweets(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r+') as file:\n",
    "            # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_dat3a with file_data\n",
    "            file_data += results\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 1)\n",
    "    else:\n",
    "        with open(filename, 'w+') as file:\n",
    "            # convert back to json.\n",
    "            json.dump(results, file, indent = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file in which to store the downloaded tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_precious_tweets_on_%s.json'%'test2'\n",
    "appendTweets(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is what I do (and have done for you :-) for getting an emergency collection of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering real data very often will run into some type of issue.  For example, lossing network connectivity.  Gathering tweets is even more tricky, since Twitter enforces rate limits.  I.e., if you gather too many tweets then Twitter will unceremoniously cut you off.  Accordingly, it is good to keep all the tweets you gather for later processing.  Here is a little loop that will gather a group of tweets on various topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Commented out so you don't run by mistake.  This will very quickly get you rate limited.\n",
    "# searches= ['Toyota', 'LG', 'election', 'restaurant', 'pizza', 'MtG', 'WoW', 'Ford', 'chocolate', 'pokemon']\n",
    "\n",
    "# for q in searches:\n",
    "#     results = twitter_search(twitter_api, q, max_results=1000)\n",
    "#     filename = 'my_precious_tweets_on_%s.json'%q\n",
    "#     appendTweets(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis of Tweets and Tweet Entities with Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read back in your tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_precious_tweets_on_%s.json'%q\n",
    "results = json.load(open(filename,'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular tweets in your collection of tweets\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "def find_popular_tweets(twitter_api, statuses, retweet_threshold=3):\n",
    "\n",
    "    # You could also consider using the favorite_count parameter as part of\n",
    "    # this heuristic, possibly using it to provide an additional boost to\n",
    "    # popular tweets in a ranked formulation\n",
    "\n",
    "    return [ status\n",
    "                for status in statuses\n",
    "                    if status['retweet_count'] > retweet_threshold ]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "popular_tweets = find_popular_tweets(twitter_api, results)\n",
    "\n",
    "for tweet in popular_tweets:\n",
    "    print(tweet['text'], tweet['retweet_count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def extract_tweet_entities(statuses):\n",
    "\n",
    "    # See https://bit.ly/2MELMkm\n",
    "    # for more details on tweet entities\n",
    "\n",
    "    if len(statuses) == 0:\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    screen_names = [ user_mention['screen_name']\n",
    "                         for status in statuses\n",
    "                            for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "    hashtags = [ hashtag['text']\n",
    "                     for status in statuses\n",
    "                        for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "    urls = [ url['expanded_url']\n",
    "                     for status in statuses\n",
    "                        for url in status['entities']['urls'] ]\n",
    "\n",
    "    # In some circumstances (such as search results), the media entity\n",
    "    # may not appear\n",
    "    medias = []\n",
    "    symbols = []\n",
    "    for status in statuses:\n",
    "        if 'media' in status['entities']:\n",
    "            for media in status['entities']['media']:\n",
    "                medias.append(media['url'])\n",
    "        if 'symbol' in status['entities']:\n",
    "            for symbol in status['entities']['symbol']:\n",
    "                symbols.append(symbol)\n",
    "\n",
    "    return screen_names, hashtags, urls, medias, symbols\n",
    "\n",
    "# Sample usage\n",
    "screen_names, hashtags, urls, media, symbols = extract_tweet_entities(results)\n",
    "\n",
    "# Explore the first five items for each...\n",
    "\n",
    "print(json.dumps(screen_names[0:5], indent=1))\n",
    "print(json.dumps(hashtags[0:5], indent=1))\n",
    "print(json.dumps(urls[0:5], indent=1))\n",
    "print(json.dumps(media[0:5], indent=1))\n",
    "print(json.dumps(symbols[0:5], indent=1))\n",
    "\n",
    "def get_common_tweet_entities(statuses, entity_threshold=3):\n",
    "\n",
    "    # Create a flat list of all tweet entities\n",
    "    tweet_entities = [  e\n",
    "                        for status in statuses\n",
    "                            for entity_type in extract_tweet_entities([status])\n",
    "                                for e in entity_type\n",
    "                     ]\n",
    "\n",
    "    c = Counter(tweet_entities).most_common()\n",
    "\n",
    "    # Compute frequencies\n",
    "    return [ (k,v)\n",
    "             for (k,v) in c\n",
    "                 if v >= entity_threshold\n",
    "           ]\n",
    "\n",
    "# Sample usage\n",
    "common_entities = get_common_tweet_entities(results)\n",
    "\n",
    "print(\"Most common tweet entities\")\n",
    "print(common_entities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw):\n",
    "\n",
    "    # A nested helper function that handles common HTTPErrors. Returns an updated\n",
    "    # value for wait_period if the problem is a 500-level error. Blocks until the\n",
    "    # rate limit is reset if it's a rate-limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which require special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "\n",
    "        if wait_period > 3600: # Seconds\n",
    "            print('Too many retries. Quitting.', file=sys.stderr)\n",
    "            raise e\n",
    "\n",
    "        # See https://developer.twitter.com/en/docs/basics/response-codes\n",
    "        # for common codes\n",
    "\n",
    "        if e.e.code == 401:\n",
    "            print('Encountered 401 Error (Not Authorized)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 429:\n",
    "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
    "            if sleep_when_rate_limited:\n",
    "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate-limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print('Encountered {0} Error. Retrying in {1} seconds'\\\n",
    "                  .format(e.e.code, wait_period), file=sys.stderr)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "\n",
    "    wait_period = 2\n",
    "    error_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError as e:\n",
    "            error_count = 0\n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"BadStatusLine encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "# See http://bit.ly/2Gcjfzr for twitter_api.users.lookup\n",
    "\n",
    "response = make_twitter_request(twitter_api.users.lookup,\n",
    "                                screen_name=\"ladygaga\")\n",
    "\n",
    "print(json.dumps(response, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 21 total friends ids for randypaffenroth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16687357, 3348826288, 40414138, 333547512, 323905099, 14755031, 119437491, 47042324, 326164900, 139790231, 466959826, 450725339, 7144422, 783214, 20536157, 14216123, 20402945, 141403992, 50393960, 14009672, 74371908]\n",
      "[2458724984, 3302333726, 4460376852, 1307064024199311367, 1198093452585656320, 423676582, 31067209, 3011086935, 33891267, 1260657884, 450725339, 2533071763, 1078413485690769409, 1554296732, 65777465, 839933639450312706, 996818600517238784, 3171620876, 3464328314, 750708195539099648, 824473421476143105, 746046557548584965, 94022997, 1183815506, 159883398, 1529017262, 189581991, 14319272, 1241871145, 466959826, 47042324, 14009672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 32 total followers ids for randypaffenroth\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from sys import maxsize as maxint\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=maxint, followers_limit=maxint):\n",
    "\n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \"Must have screen_name or user_id, but not both\"\n",
    "\n",
    "    # See http://bit.ly/2GcjKJP and http://bit.ly/2rFz90N for details\n",
    "    # on API parameters\n",
    "\n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids,\n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids,\n",
    "                                count=5000)\n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "\n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"],\n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "\n",
    "        if limit == 0: continue\n",
    "\n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "\n",
    "            # Use make_twitter_request via the partially bound callable\n",
    "            if screen_name:\n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "\n",
    "            print('Fetched {0} total {1} ids for {2}'.format(len(ids),\n",
    "                  label, (user_id or screen_name)),file=sys.stderr)\n",
    "\n",
    "            # You may want to store data during each iteration to provide an\n",
    "            # additional layer of protection from exceptional circumstances\n",
    "\n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    # Do something useful with the IDs, like store them to disk\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"randypaffenroth\",\n",
    "                                                       # screen_name=\"ladygaga\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)\n",
    "\n",
    "print(friends_ids)\n",
    "print(followers_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 5000 total friends ids for ladygaga\n",
      "Fetched 5000 total followers ids for ladygaga\n",
      "Fetched 21 total friends ids for randypaffenroth\n",
      "Fetched 31 total followers ids for randypaffenroth\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "friends_ids_1, followers_ids_1 = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"ladygaga\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)\n",
    "friends_ids_2, followers_ids_2 = get_friends_followers_ids(twitter_api,\n",
    "                                                       screen_name=\"randypaffenroth\",\n",
    "                                                       friends_limit=100,\n",
    "                                                       followers_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "friends_ids_1 = set(friends_ids_1)\n",
    "followers_ids_1 = set(followers_ids_1)\n",
    "friends_ids_2 = set(friends_ids_2)\n",
    "followers_ids_2 = set(followers_ids_2)\n",
    "\n",
    "print(friends_ids_1.intersection(friends_ids_2))\n",
    "print(followers_ids_1.intersection(followers_ids_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business question! \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_results = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'id_str', 'name', 'screen_name', 'location', 'description', 'url',\n",
       "       'entities', 'protected', 'followers_count', 'friends_count',\n",
       "       'listed_count', 'created_at', 'favourites_count', 'utc_offset',\n",
       "       'time_zone', 'geo_enabled', 'verified', 'statuses_count', 'lang',\n",
       "       'status', 'contributors_enabled', 'is_translator',\n",
       "       'is_translation_enabled', 'profile_background_color',\n",
       "       'profile_background_image_url', 'profile_background_image_url_https',\n",
       "       'profile_background_tile', 'profile_image_url',\n",
       "       'profile_image_url_https', 'profile_link_color',\n",
       "       'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
       "       'profile_text_color', 'profile_use_background_image',\n",
       "       'has_extended_profile', 'default_profile', 'default_profile_image',\n",
       "       'following', 'follow_request_sent', 'notifications', 'translator_type',\n",
       "       'withheld_in_countries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>entities</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>...</th>\n",
       "      <th>profile_text_color</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "      <th>translator_type</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14230524</td>\n",
       "      <td>14230524</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td></td>\n",
       "      <td>“Chromatica” ⚔️💓 OUT NOW https://t.co/dgVb2wLj...</td>\n",
       "      <td>https://t.co/r5yRJxbDmD</td>\n",
       "      <td>{'url': {'urls': [{'url': 'https://t.co/r5yRJx...</td>\n",
       "      <td>False</td>\n",
       "      <td>83622167</td>\n",
       "      <td>...</td>\n",
       "      <td>333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    id_str       name screen_name location  \\\n",
       "0  14230524  14230524  Lady Gaga    ladygaga            \n",
       "\n",
       "                                         description                      url  \\\n",
       "0  “Chromatica” ⚔️💓 OUT NOW https://t.co/dgVb2wLj...  https://t.co/r5yRJxbDmD   \n",
       "\n",
       "                                            entities  protected  \\\n",
       "0  {'url': {'urls': [{'url': 'https://t.co/r5yRJx...      False   \n",
       "\n",
       "   followers_count  ...  profile_text_color  profile_use_background_image  \\\n",
       "0         83622167  ...              333333                          True   \n",
       "\n",
       "  has_extended_profile  default_profile default_profile_image following  \\\n",
       "0                False            False                 False     False   \n",
       "\n",
       "   follow_request_sent  notifications  translator_type withheld_in_countries  \n",
       "0                False          False          regular                    []  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
