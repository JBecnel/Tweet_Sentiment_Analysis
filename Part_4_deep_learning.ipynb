{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/3446/1*-IPQlOd46dlsutIbUq1Zcw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desired outcome of this part.**\n",
    "* Similar to part 3 we will look at movie reviews from the v2.0 polarity dataset comes from\n",
    "the http://www.cs.cornell.edu/people/pabo/movie-review-data.\n",
    "    * It contains written reviews of movies divided into positive and negative reviews.\n",
    " \n",
    "    \n",
    "**Required Readings:** \n",
    "* This case study will be based upon the scikit-learn Python library\n",
    "* Again will build upon the turtorial \"Working With Text Data\" which can be found at http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "* Read about deep learning at https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "**Required Python libraries:**\n",
    "* Same as case study 3, except for the extra credit question.\n",
    "    * Numpy (www.numpy.org) \n",
    "    * Matplotlib (matplotlib.org) \n",
    "    * Scikit-learn (scikit-learn.org) \n",
    "    * You are also welcome to use the Python Natural Language Processing Toolkit (www.nltk.org) (though it is not required).\n",
    "    * Pytorch (www.pytorch.org)\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load in the movie review data, create TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This problem is, basically, already answered as part of part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loading\n",
      "n_samples: 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "# the training data folder must be passed as first argument\n",
    "movie_reviews_data_folder = 'txt_sentoken'\n",
    "print(\"before loading\")\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "print(\"n_samples: %d\" % len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.25, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "features = TfidfVectorizer(min_df=3, max_df=0.95, ngram_range=(1,1))\n",
    "X_train=features.fit_transform(docs_train)\n",
    "X_test=features.transform(docs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Compute a project of the original features into a lower dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the code run reasonably fast we want to reduce our number of features.  So, we use one of my favorite algorithms, Principal Component Analysis (PCA) implemented using the Singular Value Decomposition (SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8584233012463615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "\n",
    "svd = TruncatedSVD(n_components=1000)\n",
    "svd.fit(X_train)\n",
    "print(sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = svd.transform(X_train)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3:  Train Multi-Layer Perceptron classifier using the movie review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Pytorch library to implement a simple MLP.  Note you will need to install Pytorch using Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 500)\n",
    "        self.fc2 = nn.Linear(500, 400)\n",
    "        self.fc3 = nn.Linear(400, 300)\n",
    "        self.fc4 = nn.Linear(300, 200)\n",
    "        self.fc5 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        intermediate_vector1 = F.relu(self.fc1(input))\n",
    "        intermediate_vector2 = F.relu(self.fc2(intermediate_vector1))\n",
    "        intermediate_vector3 = F.relu(self.fc3(intermediate_vector2))\n",
    "        intermediate_vector4 = F.relu(self.fc4(intermediate_vector3))\n",
    "        prediction_vector = torch.sigmoid(self.fc5(intermediate_vector4))\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier() \n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(mlp.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a few minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed.\n",
      "Epoch 50 completed.\n",
      "Epoch 75 completed.\n",
      "Epoch 100 completed.\n",
      "Epoch 125 completed.\n",
      "Epoch 150 completed.\n",
      "Epoch 175 completed.\n",
      "Epoch 200 completed.\n",
      "Epoch 225 completed.\n",
      "Epoch 250 completed.\n",
      "Epoch 275 completed.\n",
      "Epoch 300 completed.\n",
      "Epoch 325 completed.\n",
      "Epoch 350 completed.\n",
      "Epoch 375 completed.\n",
      "Epoch 400 completed.\n",
      "Epoch 425 completed.\n",
      "Epoch 450 completed.\n",
      "Epoch 475 completed.\n",
      "Epoch 500 completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "y_train = y_train.reshape(-1,1)\n",
    "\n",
    "for i in range(1, num_epochs+1):\n",
    "    # the training routine is these 5 steps:\n",
    "    # step 1. zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # step 2. compute the output\n",
    "    y_pred = mlp(X_train.float())\n",
    "\n",
    "    # step 3. compute the loss\n",
    "    loss = loss_func(y_pred, torch.tensor(y_train, dtype=torch.float))\n",
    "\n",
    "    # step 4. use loss to produce gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # step 5. use optimizer to take gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 25 == 0:\n",
    "        print('Epoch ' + str(i)  + ' completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = mlp(X_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = (torch.round(y_predicted)).detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[178  73]\n",
      " [ 18 231]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b7a7836fd0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.scatter(range(len(y_predicted)), y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put all the pieces together:\n",
    "\n",
    "1. We get data from our MongoDB data using a interesting query\n",
    "1. We leverage all of our pretrained algorithms\n",
    "1. We make predictions on a new dataset using (simple) transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'Toyota'\n",
    "    \n",
    "# The connection string for a remote hosted mongodb running on MongoDB atlas\n",
    "# client = pymongo.MongoClient(\"mongodb+srv://test:epsabre@cluster0.fup2q.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")\n",
    "# A local mongodb running on your personal machine installed from using the documentation:\n",
    "#    https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/ \n",
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017\")\n",
    "# Get a reference to a particular database\n",
    "    \n",
    "db = client['twitter']\n",
    "    \n",
    "# Reference a particular collection in the database\n",
    "coll = db['statuses_'+q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a search!  See \n",
    "# https://docs.mongodb.org/getting-started/python/query/\n",
    "# and\n",
    "# https://docs.mongodb.org/manual/tutorial/query-documents/\n",
    "# for details.\n",
    "\n",
    "#cursor = coll.find({'$or': [ {'retweeted': 'true'} ,\n",
    "#                            {'text':  {'$regex': '.*car.*', '$options': 'i' }} ] })\n",
    "#cursor = coll.find({'metadata.iso_language_code': {'$eq': 'en'}})\n",
    "cursor = coll.find({'$and' : [{'metadata.iso_language_code': {'$eq': 'en'}},\n",
    "                              {'$or': [ {'retweeted': 'true'} ,\n",
    "                                        {'text':  {'$regex': '.*car.*', '$options': 'i' }} ] }]})\n",
    "X_tweet = []\n",
    "for tweet in cursor:\n",
    "    X_tweet.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweet_features = features.transform(X_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small visualziation to make sure that our movie review features and our tweets have at least some overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1b79482c6d8>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.spy(X_tweet_features[:,:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our pretrained preprocessing chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweet_features_projected = svd.transform(X_tweet_features)\n",
    "X_tweet_features_projected = torch.from_numpy(X_tweet_features_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our pretrained neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tweet_predicted = mlp(X_tweet_features_projected.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we get something reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @carandbike: The 1994 #ToyotaSupra driven by the late #PaulWalker in the Fast and the Furious franchise has been auctioned for a whoppinâ€¦\n",
      "tensor([0.8671], grad_fn=<SelectBackward>)\n",
      "\n",
      "the toyota dealer has my fkin car bitch â€¦ my saga of pain is over\n",
      "tensor([1.0000], grad_fn=<SelectBackward>)\n",
      "\n",
      "Toyota is giving folks manicures while waiting for their car to get serviced ðŸ˜Œ thatâ€™s nice .\n",
      "tensor([1.0000], grad_fn=<SelectBackward>)\n",
      "\n",
      "@lm_irish Iszuzu rodeo, 1972 Volvo s70(turned over the odometer twice actually and it was my momâ€™s first car then mâ€¦ https://t.co/ZXshYgEcGO\n",
      "tensor([4.4379e-05], grad_fn=<SelectBackward>)\n",
      "\n",
      "@ForzaHorizon i can't wait, btw the Lambo Sesto Elemento, Nissan skyline r34 and Toyota supra 98 best be included in the car list\n",
      "tensor([0.9628], grad_fn=<SelectBackward>)\n",
      "\n",
      "2014 Toyota Succeed Wagon https://t.co/bymjBsri4I #usedcar #vehicle #tradecarview\n",
      "tensor([1.0000], grad_fn=<SelectBackward>)\n",
      "\n",
      "RT @Lionel_Racing: Celebrate Kyle Busch's 100th career NASCAR Xfinity Series victory with the official Raced-Win die-cast of the No. 54 M&amp;Mâ€¦\n",
      "tensor([4.1228e-06], grad_fn=<SelectBackward>)\n",
      "\n",
      "@allenliberty We're happy to hear that our friends at Toyota of Newnan were able to get you into the car of your drâ€¦ https://t.co/L7JOPyEZQF\n",
      "tensor([1.], grad_fn=<SelectBackward>)\n",
      "\n",
      "RT @CARandDRIVER: What do you think of the 2022 @Toyota Tundra TRD Pro? https://t.co/oLJOMCBq3J https://t.co/E2SGfVSkKc\n",
      "tensor([0.9712], grad_fn=<SelectBackward>)\n",
      "\n",
      "@nematombo @SmangaMad @gamuchete @CruizAutoCity @PTChimusoro @thembakumbula @phillipkudzayi @Cars05zw It's a greatâ€¦ https://t.co/zjJYXB31cN\n",
      "tensor([1.0000], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(X_tweet[i])\n",
    "    print(y_tweet_predicted[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big question - How to improve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
